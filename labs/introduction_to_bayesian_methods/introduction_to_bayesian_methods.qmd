---
title: "Introduction to Bayesian Methods"
subtitle: "SHARP Bayesian Modeling for Environmental Health Workshop"
author: "Robbie M. Parks"
date: "August 2023"
output: html_document
---

```{r, echo=FALSE, warning=FALSE, message=FALSE}
library(here)
library(tidyverse)
library(nimble)
library(bayesplot)
library(posterior)
library(hrbrthemes)

extrafont::loadfonts()
theme_set(theme_ipsum())

color_scheme_set(scheme = "viridis")

set.seed(2)
```

## Goal of this computing lab session

This lab will involve taking some concepts from the lectures and introduce you to the way NIMBLE works.

## Introduction to NIMBLE format.

NIMBLE is written in a slightly unusual format if you're used to just using R. It is written in the style of a program called BUGS, which came out a few decades ago and was developed at Imperial College London.

## First basic examples of NIMBLE and how to use it.

These examples will be for basic regression models using linear predictors

Adapted from https://r-nimble.org/examples

## Normal-Normal example.

The first example will utilize a simple regression

First create some example data for our model:

$$
y = max + c
$$
```{r}
set.seed(1)

p <- 3    # number of explanatory variables
n <- 100   # number of observations
X <- matrix(round(rnorm(p * n), 2), nrow = n, ncol = p) # explanatory variables
true_betas <- c(c(0.2, 0.5, 0.3)) # coefficients
sigma <- 0.5
y <- rnorm(n, X %*% true_betas, sigma)
```

What does the dataset look like?
```{r}
df <- tibble(y = y, x1 = X[,1], x2 = X[,2], x3 = X[,3])
df
```

What does equivalent frequentist model output look like for reference? What's the interpretation of the 95% CI?
```{r}
model_freq <- lm(
  y ~ x1 + x2 + x3,
  data = df
)
central_est <- t(t(model_freq$coefficients))
conf_int <- confint(model_freq)
cbind(central_est, conf_int)
```

Create the NIMBLE model
```{r}
code <- nimbleCode({
  # priors for parameters
  alpha ~ dnorm(0, sd = 100) # prior for alpha
  beta1 ~ dnorm(0, sd = 100) # prior for beta1
  beta2 ~ dnorm(0, sd = 100) # prior for beta2
  beta3 ~ dnorm(0, sd = 100) # prior for beta3
  sigma ~ dunif(0, 100)      # prior for variance components

  # regression formula
  for(i in 1:n) {
    mu[i] <- alpha + beta1 * x1[i] + beta2 * x2[i] + beta3 * x3[i] # manual entry of linear predictors
    y[i] ~ dnorm(mu[i], sd = sigma)
  }

})
```

Before running NIMBLE, extract data for three predictors and center around zero for better MCMC performance
```{r}
x1 <- X[,1] - mean(X[,1])
x2 <- X[,2] - mean(X[,2])
x3 <- X[,3] - mean(X[,3])
```

Final preparation of data into lists
```{r}
constants <- list(n = n)
data <- list(y = y, x1 = x1, x2 = x2, x3 = x3)
```

Set initial values for MCMC samples
```{r}
inits <- list(beta0 = mean(y), alpha = 0, beta2 = 0, beta3 = 0, sigma = 1)
```

The following code will establish which samples will be used in the sampling of the posteriors. If there is a conjugate relationship apparent between prior and posterior (e.g., Normal-Normal, Binomial-Beta, Poisson-Gamma), it will be detected here
```{r}
model <- nimbleModel(code, constants = constants, data = data, inits = inits)
mcmcConf <- configureMCMC(model)
```

Run the MCMC simulations
```{r}
t0 = Sys.time()
nimbleMCMC_samples_initial <- nimbleMCMC(
  code = code,
  data = data,
  constants = constants,
  inits = inits,
  niter = 10000, # run 10000 samples
  setSeed = 1,
  samplesAsCodaMCMC = TRUE
)

t1 =  Sys.time()
t1 - t0
```

What is the summary of each estimated parameter from the samples?
```{r}
summarise_draws(nimbleMCMC_samples_initial, default_summary_measures())
summarise_draws(nimbleMCMC_samples_initial, default_convergence_measures())
```

What do the samples of one of the unknown parameters actually look like? Let's have a look at beta1 (which we know is 0.2)
```{r}
mcmc_trace(nimbleMCMC_samples_initial)
```

So it looks like the samples are converging quickly from the initial parameter to ~0.2. But typically we will throw some samples at the beginning to ensure that the transient samples (which is when the model samples haven't stabilized around a particular value) are not included in calculating estimates of the mean and credible intervals. This is called the 'burn in' or 'warm up period'.

Let's do it again but with a burn in of 1000 samples.
```{r}
t0 = Sys.time()
nimbleMCMC_samples_burnin <- nimbleMCMC(
  code = code,
  data = data,
  constants = constants,
  inits = inits,
  niter = 10000,  # collect 10000 samples
  nburnin = 1000, # burn in for 1000 iterations
  setSeed = 1,
  samplesAsCodaMCMC = TRUE
)

t1 =  Sys.time()
t1 - t0
```

What is the summary of each estimated parameter from the samples with burn in?
```{r}
summarise_draws(nimbleMCMC_samples_burnin, default_summary_measures())
```

Now the samples look to be very tidily centred around 0.2.
```{r}
mcmc_trace(nimbleMCMC_samples_burnin)
```

What's the influence of tighter priors?
```{r}
code_tighter_priors <- nimbleCode({
  # priors for parameters
  alpha ~ dnorm(0, sd = 1) # prior for alpha
  beta1 ~ dnorm(0, sd = 1) # prior for beta1
  beta2 ~ dnorm(0, sd = 1) # prior for beta2
  beta3 ~ dnorm(0, sd = 1) # prior for beta3
  sigma ~ dunif(0, 1)      # prior for variance components

  # regression formula
  for(i in 1:n) {
    mu[i] <- alpha + beta1*x1[i] + beta2*x2[i] + beta3*x3[i] # manual entry of linear predictors
    y[i] ~ dnorm(mu[i], sd = sigma)
  }
})
```

Run the MCMC simulations
```{r}
t0 = Sys.time()
nimbleMCMC_samples_tighter_priors <- nimbleMCMC(
  code = code_tighter_priors,
  data = data,
  constants = constants,
  inits = inits,
  niter = 10000,
  nburnin = 1000,
  setSeed = 1,
  samplesAsCodaMCMC = TRUE
)

t1 =  Sys.time()
t1 - t0
```

What is the summary of each estimated parameter from the samples with tighter priors?
```{r}
summarise_draws(nimbleMCMC_samples_tighter_priors, default_summary_measures())
```

Say we wanted to establish the estimated difference between two betas? Let's say `beta_1` and `beta_2` in this case
```{r}
code_diff_betas <- nimbleCode({
  # priors for parameters
  alpha ~ dnorm(0, sd = 100) # prior for alpha
  beta1 ~ dnorm(0, sd = 100) # prior for beta1
  beta2 ~ dnorm(0, sd = 100) # prior for beta2
  beta3 ~ dnorm(0, sd = 100) # prior for beta3
  sigma ~ dunif(0, 100)      # prior for variance components

  # regression formula
  for(i in 1:n) {
    mu[i] <- alpha + beta1*x1[i] + beta2*x2[i] + beta3*x3[i]
    y[i] ~ dnorm(mu[i], sd = sigma)
  }

  # difference between beta1 and beta2
  beta12_diff <- beta2 - beta1

})
```

Run the MCMC simulations for monitoring specifically differences between beta1 and beta2
```{r}
parameters_to_monitor = c('beta12_diff')

t0 = Sys.time()
nimbleMCMC_samples_beta12_diff = nimbleMCMC(
  code = code_diff_betas,
  data = data,
  constants = constants,
  inits = inits,
  monitors = parameters_to_monitor,
  niter = 10000,
  nburnin = 1000,
  setSeed = 1,
  samplesAsCodaMCMC = TRUE
)

t1 =  Sys.time()
t1 - t0
```

What is the summary of each estimated parameter from the samples when monitoring difference between beta1 and beta2?
```{r}
summarise_draws(nimbleMCMC_samples_beta12_diff, default_summary_measures())
```

Equally, we could do this by operating on the samples themselves from the original model.
```{r}
(nimbleMCMC_samples_burnin[, "beta2"] - nimbleMCMC_samples_burnin[, "beta1"]) |> as.numeric() |> summary()
```

## Logistic regression example.

First create some example data for our model:

$$
y = max + c
$$

```{r}
n <- 10000
p <- 3

set.seed(1)
x1 <- round(rnorm(n), 2)
x2 <- round(rnorm(n), 2)
x3 <- round(rnorm(n), 2)

z <- 1 + 2 * x1 + 3 * x2 - 5 * x3 # linear combination with a bias
pr <- 1 / (1 + exp(-z))           # pass through an inv-logit function
y <- rbinom(n, 1, pr)             # bernoulli response variable
```

What does the dataset look like?
```{r}
df <- tibble(y = y, x1 = x1, x2 = x2, x3 = x3)
df
```

What does equivalent frequentist model output look like for reference? What's the interpretation of the 95% CI?
```{r}
# now feed it to glm:
model_freq = glm(
  y ~ x1 + x2 + x3,
  family = "binomial",
  data = df
)

central_est = t(t(model_freq$coefficients))
conf_int = confint(model_freq)
cbind(central_est, conf_int)
```

Create the NIMBLE model
```{r}
code_binomial <- nimbleCode({
  # priors for parameters
  alpha ~ dnorm(0, sd = 100) # prior for alpha
  beta1 ~ dnorm(0, sd = 100) # prior for beta1
  beta2 ~ dnorm(0, sd = 100) # prior for beta2
  beta3 ~ dnorm(0, sd = 100) # prior for beta3

  # regression formula
  for(i in 1:n) {
    y[i] ~ dbin(p[i], 1)
    logit(p[i]) <- alpha + beta1 * x1[i] + beta2 * x2[i] + beta3 * x3[i]
  }

})
```

Before running NIMBLE, extract data for three predictors and center around zero for better MCMC performance
```{r}
x1 <- x1 - mean(x1)
x2 <- x2 - mean(x2)
x3 <- x3 - mean(x3)
```

Final preparation of data into lists
```{r}
constants <- list(n = n)
data <- list(y = y, x1 = x1, x2 = x2, x3 = x3)
```

Set initial values for MCMC samples
```{r}
inits <- list(alpha = 0, beta1 = 0, beta2 = 0, beta3 = 0)
```

The following code will establish which samples will be used in the sampling of the posteriors. If there is a conjugate relationship apparent between prior and posterior (e.g., Normal-Normal, Binomial-Beta, Poisson-Gamma), it will be detected here
```{r}
model_binomial <- nimbleModel(code_binomial, constants = constants, data = data, inits = inits)
mcmcConf <- configureMCMC(model_binomial)
```

Let's run the model.
```{r}
t0 = Sys.time()

nimbleMCMC_samples_binomial <- nimbleMCMC(
  code = code_binomial,
  data = data,
  constants = constants,
  inits = inits,
  niter = 10000,
  nburnin = 1000,
  setSeed = 1,
  samplesAsCodaMCMC = TRUE
)

t1 =  Sys.time()
t1 - t0
```

What is the summary of each estimated parameter from the binomial model?
```{r}
summarise_draws(nimbleMCMC_samples_binomial, default_summary_measures())
summarise_draws(nimbleMCMC_samples_binomial, default_convergence_measures())
```

Now the samples look to be very tidily centered around 2.
```{r}
mcmc_trace(nimbleMCMC_samples_binomial)
```

## Poisson-Gamma example.

First create some example data for our model:

$$
y = max + c
$$

```{r}
n = 10000

set.seed(1)
x1 <- round(rnorm(n), 2)
x2 <- round(rnorm(n), 2)
x3 <- round(rnorm(n), 2)

z = 4 + 0.3 * x1 - 0.1 * x2 + 0.6 * x3
lambda = exp(z)
y = rpois(n, lambda)
```

What does the dataset look like?
```{r}
df <- tibble(y = y, x1 = x1, x2 = x2, x3 = x3)
df
```

What does equivalent frequentist model output look like for reference? What's the interpretation of the 95% CI?
```{r}
# now feed it to glm:
model_freq = glm(
  y ~ x1 + x2 + x3,
  family = "poisson",
  data = df
)

central_est = t(t(model_freq$coefficients))
conf_int = confint(model_freq)
cbind(central_est, conf_int)
```

Create the NIMBLE model
```{r}
code_poisson <- nimbleCode({

  # priors for parameters
  alpha ~ dnorm(0, sd = 100) # prior for alpha
  beta1 ~ dnorm(0, sd = 100) # prior for beta1
  beta2 ~ dnorm(0, sd = 100) # prior for beta2
  beta3 ~ dnorm(0, sd = 100) # prior for beta3

  # regression formula
  for(i in 1:n) {
    y[i] ~ dpois(lambda[i])
    log(lambda[i]) <- alpha + beta1 * x1[i] + beta2 * x2[i] + beta3 * x3[i]
  }

})
```

Before running NIMBLE, extract data for three predictors and center around zero for better MCMC performance
```{r}
x1 <- x1 - mean(x1)
x2 <- x2 - mean(x2)
x3 <- x3 - mean(x3)
```

Final preparation of data into lists
```{r}
constants <- list(n = n)
data <- list(y = y, x1 = x1, x2 = x2, x3 = x3)
```

Set initial values for MCMC samples
```{r}
inits <- list(alpha = 0, beta1 = 0, beta2 = 0, beta3 = 0)
```

The following code will establish which samples will be used in the sampling of the posteriors. If there is a conjugate relationship apparent between prior and posterior (e.g., Normal-Normal, Binomial-Beta, Poisson-Gamma), it will be detected here
```{r}
model_poisson <- nimbleModel(code_poisson, constants = constants, data = data, inits = inits)
mcmcConf <- configureMCMC(model_poisson)
```

Let's run the model.
```{r}
t0 = Sys.time()
nimbleMCMC_samples_poisson <- nimbleMCMC(
  code = code_poisson,
  data = data,
  constants = constants,
  inits = inits,
  niter = 10000,
  nburnin = 1000,
  setSeed = 1,
  samplesAsCodaMCMC = TRUE
)

t1 =  Sys.time()
t1 - t0
```

What is the summary of each estimated parameter from the Poisson model?
```{r}
summarise_draws(nimbleMCMC_samples_poisson, default_summary_measures())
summarise_draws(nimbleMCMC_samples_poisson, default_convergence_measures())
```

Now the samples look to be very tidily centred around 0.3.
```{r}
mcmc_trace(nimbleMCMC_samples_poisson)
```
