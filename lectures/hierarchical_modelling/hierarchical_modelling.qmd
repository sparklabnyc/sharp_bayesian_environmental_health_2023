---
title: "Hierarchical Bayesian modelling"
subtitle: ""
author:
 - name: "Elizaveta Semenova"
   email: "elizaveta.p.semenova@gmail.com"
institute: "Computer Science Department, University of Oxford"
date: 2023-08-14
date-format: medium
title-slide-attributes:
  data-background-color: "#f3f4f4"
  data-background-image: "../../assets/bmeh_normal.png"
  data-background-size: 80%
  data-background-position: 60% 120%
format:
  revealjs:
    slide-number: true
    incremental: true
    chalkboard:
      buttons: false
      preview-links: auto
    logo: "../../assets/bmeh_normal.png"
    theme: [default, ../../assets/style.scss]
---

# Outline

-   Recap: assumptions of linear models
-   Why is that not enough?
-   Two extremes of hierarchy
-   Complete, partial and no pooling
-   Random effects
-   Types of nestedness



# Assumptions of linear models
-   Homoskedasticity
-   No error in predictors $X$
-   No missing data
-   Normally distributed errors
-   Error in $Y$ variable is measurement error
-   Observations $Y_i$ are independent

# We want
-   To model variance
-   Capture errors in variables
-   Missing data models
-   Use GLMs
-   Use spatial and/or temporal error structure

# Hierarchical models

Exist on the continuum of two extreme cases:

# Hierarchical models
(picture of complete pooling)

# Hierarchical models

A common mean across all data:
$$E(Y_1)= m$$
$$E(Y_2)= m$$
$$E(Y_3)= m$$

# Hierarchical models

A common mean across data:
$$E(Y_i)= m, \quad i=1,..., n$$


-   It ignores any differences between measurement blocks and does not acknowledge variability block to block.

-   Observation within each unit are more likely to be like each other.


# Hierarchical models

Independent model for each of the datasets:
$$E(Y_1)= m1$$
$$E(Y_2)= m2$$
$$E(Y_3)= m3$$

# Hierarchical models
(picture of independent models)

# Hierarchical models

Independent models for each of the datasets:
$$E(Y_i)= m_i, \quad i=1,...,n$$

-   Captures variability, but not the overall pattern
-   Assummes that there is no relashionship between the means of models 
-   We might be interested in capturing information across the datasets
-   Does not provide ways to extrapolate


# Hierarchical models
(picture of hierarchical structure)


# Hierarchical models

Hierarchical models fill in the continuum between those two extremes. 
hey allow us to estimate models for each measurement block where each dataset is being fit to its own model, and
then there is a higher level model - a hierarchical model - describing variability in parameters of those models.

$$E(Y_i)=\theta_i$$
$$E(\theta_i)=m$$

# Hierarchical models
-   Variablility can be captured at different scales
-   We can make predictions


# Example
Normal model - common mean

$$Y \sim N(\mu, \sigma^2) $$

# Example

Normal model - common variance

$$Y_i \sim N(\mu_i, \sigma^2) $$
$$\mu_i \sim N(\mu, \tau^2) $$
$$\sigma^2 \sim IG(\alpha, \beta) $$

Instead of assuming that $\mu$ and $\tau$ are fixed known values, we assume they are uknown parameters which need to get estimated.


# Example

Normal model - common variance

$$Y_i \sim N(\mu_i, \sigma^2) $$
$$\mu_i \sim N(\mu, \tau^2) $$
$$\sigma^2 \sim IG(\alpha, \beta) $$
Hyperpriors

$$ \mu \sim N(\mu_0, v_0), \tau^2 \sim IG(t_1, t_2)$$

# Hierarchy

-   Data model -> 
-   Proess model -> 
-   Parameter mdel -> 
-   Hyperparameters

# Key points about hierarchical models
-   Writing down models that explain variability in the parameters of a model
-   Partition variabilty more explicitely into multiple terms
-   Borrow strength across data sets
-   'Hierarchy' is with respoect to parameters

# Random effects

# Nestedness




# References

# Unused notes

* Data can have several types of structure. Including nestedness, which we call “hierarchical”.

* hierarchical models: nested models, multi-level models

* pooled model: ignore the grouping structure
- important information is neglected

* unpooled: model each group separately
— many distinct groups
— some groups have small sample size

* partial pooling, hierarchical modellingi
— complexity
