{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"Bayesian workflow\"\n",
        "subtitle: \"Good practice of Bayesian inference\"\n",
        "author:\n",
        " - name: \"Elizaveta Semenova\"\n",
        "   email: \"elizaveta.p.semenova@gmail.com\"\n",
        "institute: \"Computer Science Department, University of Oxford\"\n",
        "date: 2023-08-14\n",
        "date-format: medium\n",
        "title-slide-attributes:\n",
        "  data-background-color: \"#f3f4f4\"\n",
        "  data-background-image: \"../../assets/bmeh_normal.png\"\n",
        "  data-background-size: 80%\n",
        "  data-background-position: 60% 120%\n",
        "format:\n",
        "  revealjs:\n",
        "    slide-number: true\n",
        "    incremental: true\n",
        "    chalkboard:\n",
        "      buttons: false\n",
        "      preview-links: auto\n",
        "    logo: \"../../assets/bmeh_normal.png\"\n",
        "    theme: [default, ../../assets/style.scss]\n",
        "---"
      ],
      "id": "52631505"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Outline\n",
        "\n",
        "- Bayesian inference recap: What? Why? How?\n",
        "- What is a Bayesian workflow and why do we need it?\n",
        "- Principles of Bayesian workflow\n",
        "- Modern Bayesian workflow\n",
        "\n",
        "# Bayesian inference\n",
        "\n",
        "## Bayes formula:\n",
        "\n",
        " $$p(\\theta|y) = \\frac{p(y | \\theta) p(\\theta)}{p(y)}$$\n",
        "Can you recall what the components of the Bayes formula are?\n",
        "\n",
        "![](assets/bmeh_normal.png){.r-stretch}\n",
        "\n",
        "## Bayes formula:\n",
        "\n",
        " $$p(\\theta|y) = \\frac{p(y | \\theta) p(\\theta)}{p(y)}$$\n",
        "Can you recall what the components of the Bayes formula are?\n",
        "\n",
        "![](assets/bmeh_normal.png){.r-stretch}\n",
        "\n",
        "- $p(\\theta)$ is the *prior* distribution, i.e. what is known *a priori*\n",
        "- $p(y|\\theta)$ is the *likelihood*, i.e. probability of observing the data given parameters $\\theta$\n",
        "- $p(\\theta|y)$ is the *posterior* distribution, i.e. the distribution of parameters of interest after data were observed\n",
        "\n",
        "\n",
        "## Bayes rule:\n",
        "\n",
        "$$\\underbrace{p(\\theta|y)}_\\text{posterior} \\propto \\underbrace{p(y | \\theta)}_{\\text{likelihood}}  \\underbrace{p(\\theta)}_{\\text{prior}}$$\n",
        "\n",
        ". . .\n",
        "\n",
        "\n",
        "What can possibly go wrong?\n",
        "\n",
        ". . .\n",
        "\n",
        "A lot can go wrong!\n",
        "\n",
        "\n",
        "## General principle of Bayesian inference:\n",
        "\n",
        "- Specify a complete Bayesian model:\n",
        "  - specify likelihood\n",
        "  - specify priors for all parameters (saying \"I don't know\" is also a prior)\n",
        "    \n",
        "## General principle of Bayesian inference:\n",
        "\n",
        "- Example:\n",
        "  - consider <ins>data</ins> $y = \\{ y_1, ..., y_n\\}$\n",
        "  - specify an <ins>observation model</ins>, e.g. $$p(y|\\theta) = \\prod_i N(y_i | \\theta, \\sigma^2)$$\n",
        "   <!-- - here $\\theta$ is a parameter which we want to infer-->\n",
        "  - complete the model with a prior distribution, e.g. $$p(\\theta)=N(0,1)$$\n",
        "\n",
        "\n",
        "## General principle of Bayesian inference:\n",
        "\n",
        "- Specify a complete Bayesian model\n",
        "- Sample the posterior distribution of the parameter $\\theta$.\n",
        "  \n",
        ". . .\n",
        "\n",
        "Sometimes posterior is available in a closed form. \n",
        "\n",
        ". . .\n",
        "\n",
        "But rarely.\n",
        "\n",
        "## Probabilistic programming languages\n",
        "\n",
        "Probabilistic programming languages (PPLs) from a user's perspective:\n",
        "\n",
        "- PPLs are designed to let the user <ins>focus on modelling</ins> while inference happens automatically.\n",
        "- Users need to specify\n",
        "  - prior,\n",
        "  - likelihood.\n",
        "- Inference is performed via powerful algorithms such as, for example, Markov Chain Monte Carlo (<ins>MCMC</ins>).\n",
        "- Availability of <ins>diagnostic tools</ins>.\n",
        "\n",
        "## Remark on inference methods\n",
        "\n",
        "- Alongside \"exact\"methods such as MCMC, there also exist approximate methods, such as Variation Inference (VI). \n",
        "- We are opting to use MCMC whenever possible since it has theoretical guarantees.\n",
        "\n",
        "\n",
        "## Diagnosing MCMC outputs\n",
        "\n",
        "We use multiple chains of MCMC to estimate the posterior:\n",
        "\n",
        ". . .\n",
        "\n",
        "<center>\n",
        "![](assets/trace_theta.png){width=50%}\n",
        "\n",
        "\n",
        "\n",
        "## Diagnosing MCMC outputs\n",
        "\n",
        "- <ins>Convergence diagnostics</ins>\n",
        "  - $\\hat{R}$ statistic,\n",
        "  - traceplots.\n",
        "- <ins>Effective sample size (ESS)</ins>:\n",
        "  - samples will be typically autocorrelated within a chain, which increases the uncertainty of the estimation of posterior quantities,\n",
        "  - ESS -- number of *independent* samples required to obtain the same level of uncertainty as from the available dependent samples.\n",
        "\n",
        "## Diagnosing MCMC outputs\n",
        "\n",
        "We use multiple chains of MCMC to inspect convergence after warm-up:\n",
        "\n",
        ". . .\n",
        "\n",
        "<center>\n",
        "![](assets/trace_theta.png){width=50%} \n",
        "\n",
        "\n",
        "\n",
        "## Diagnosing MCMC outputs\n",
        "\n",
        "We use multiple chains and inspect convergence after warm-up:\n",
        "\n",
        ". . .\n",
        "\n",
        "<center>\n",
        "![](assets/trace_theta_bad.png){width=50%} \n",
        "\n",
        "\n",
        "\n",
        "## Diagnosing MCMC outputs\n",
        "\n",
        "The post-warm-up samples of $\\theta$ approximate its posterior distribution:\n",
        "\n",
        ". . .\n",
        "\n",
        "<center>\n",
        "![](assets/post_theta.png){width=50%}\n",
        "\n",
        "# Principles of Bayesian workflow\n",
        "\n",
        "## Workflows as a 'good practice'\n",
        "\n",
        "Workflows exist in a variety of disciplines. For example, in machine learning workflow standards are being formalised under the name of MLOps:\n",
        "\n",
        "<center>\n",
        "![](assets/mlops-loop-en.png){width=50%}\n",
        "\n",
        "\n",
        "## Box's loop\n",
        "\n",
        "In the 1960's, the statistician Box formulated the notion of a loop to understand the nature of the scientific method. This loop is called Box's loop by Blei et. al. (2014):\n",
        "\n",
        "<center>\n",
        "![](assets/boxes_loop.png){width=60%} \n",
        "\n",
        "## Modern Bayesian workflow\n",
        "\n",
        "A systematic review of the steps within the modern Bayesian workflow, described in Gelman et al. (2020):\n",
        "\n",
        "<center>\n",
        "![](assets/bayes_workflow.png){width=40%} \n",
        "\n",
        "## Prior predictive checks\n",
        "\n",
        "<ins>Prior predictive checking</ins> consists in simulating data from the priors:\n",
        "\n",
        "- visualize priors (especially after transformation),\n",
        "\n",
        "- this shows the range of data compatible with the model,\n",
        "\n",
        "- it helps understand the adequacy of the chosen priors, as it is often easier to elicit expert knowledge on measureable quantities of interest rather than abstract parameter values.\n",
        "\n",
        "\n",
        "## Iterative model building\n",
        "\n",
        "A possible realisation of the Bayeisan workflow loop:\n",
        "\n",
        "- Understand the <ins>domain</ins> and problem,\n",
        "\n",
        "- Formulate the model <ins>mathematically</ins>,\n",
        "\n",
        "- Implement model, test, <ins>debug</ins>,\n",
        "\n",
        "- <ins>debug, debug, debug</ins>\n",
        "\n",
        "\n",
        "## Iterative model building\n",
        "\n",
        "- Understand the <ins>domain</ins> and problem,\n",
        "\n",
        "- Formulate the model <ins>mathematically</ins>,\n",
        "\n",
        "- Implement model, test, <ins>debug</ins>,\n",
        "\n",
        "- Perform <ins>prior predictive</ins> check,\n",
        "\n",
        "- Fit the model,\n",
        "\n",
        "- Assess <ins>convergence diagnostics</ins>,\n",
        "\n",
        "- Perform <ins>posterior predictive</ins> check,\n",
        "\n",
        "- Improve the model <ins>iteratively</ins>: from baseline to complex and computationally efficient models.\n",
        "\n",
        "# Examples\n",
        "\n",
        "## Data\n",
        "Assume that the true data comes from the model\n",
        "$$y_i = a + b x_i + \\epsilon_i, \\quad \\epsilon_i \\sim N(0, \\sigma^2).$$\n",
        "\n",
        "<center>\n",
        "![](assets/data1.png){width=45%} \n",
        "\n",
        "\n",
        "\n",
        "## Model\n",
        "We implemented the model in our favorite PPL:\n",
        "\n",
        ". . .\n"
      ],
      "id": "0bb679ea"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "data {\n",
        "  int<lower=0> N;\n",
        "  vector[N] y;\n",
        "  vector[N] x;\n",
        "  real<lower=0> sigma;\n",
        "}\n",
        "parameters {\n",
        "  real a;\n",
        "  real b;\n",
        "}\n",
        "model {\n",
        "  y ~ normal(a, sigma);\n",
        "}"
      ],
      "id": "9a14fac7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Prior predictive check\n",
        "Let us draw from the priors, i.e. we are not using any data at this stage, only trying to see what kind of data ($y$) this model is able to generate.\n",
        "\n",
        ". . .\n",
        "\n",
        "<center>\n",
        "![](assets/data2.png){width=45%} \n",
        "\n",
        "(add uncertainty bounds)\n",
        "\n",
        "## Prior predictive check\n",
        "Something doesn't look right...\n",
        "\n",
        ". . .\n",
        "\n",
        "<center>\n",
        "![](assets/data2.png){width=45%} \n",
        "\n",
        "\n",
        "## Debug\n",
        "There was a bug in the model. Let's correct it:\n",
        "\n",
        "```\n",
        "data {\n",
        "  int<lower=0> N;\n",
        "  vector[N] y;\n",
        "  vector[N] x;\n",
        "  real<lower=0> sigma;\n",
        "}\n",
        "parameters {\n",
        "  real a ~ normal(0,1);\n",
        "  real b ~ normal(0,1);\n",
        "}\n",
        "model {\n",
        "  y ~ normal(a + b*x, sigma);\n",
        "}\n",
        "```\n",
        "\n",
        "## Prior redictive check again\n",
        "<center>\n",
        "![](assets/data3.png){width=45%} \n",
        "\n",
        "Better: now the range of prior predictive distribution is covering the data.\n",
        "\n",
        "(add uncertainty bounds)\n",
        "\n",
        "\n",
        "## Fit the model\n",
        "Print summary:\n",
        "<center>\n",
        "![](assets/fit1.png){width=60%} \n",
        "\n",
        "## Plot estimates\n",
        "<center>\n",
        "![](assets/est1.png){width=45%} \n",
        "\n",
        "\n",
        "## Convergence diagnostics\n",
        "\n",
        "\n",
        "<center>\n",
        "![](assets/fit1_conv.png){width=60%} \n",
        "\n",
        "\n",
        "## Convergence diagnostics\n",
        "\n",
        "Traceplots\n",
        "\n",
        "<center>\n",
        "![](assets/traceplots1.png){width=45%} \n",
        "\n",
        "## Posterior predictive check\n",
        "\n",
        "<center>\n",
        "![](assets/posterior1.png){width=45%} \n",
        "\n",
        "(add uncertainty bounds)\n",
        "\n",
        "# References"
      ],
      "id": "0671e6d7"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
